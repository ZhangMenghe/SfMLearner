{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from depth2normal_tf import *\n",
    "from normal2depth_tf import *\n",
    "import numpy as np\n",
    "from kitti_eval.depth_evaluation_utils import *\n",
    "\n",
    "gt_path = '../raw_data_downloader/kitti-val/'\n",
    "test_filelst = './data/kitti/test_files_eigen.txt'\n",
    "test_files = read_text_lines(test_filelst)\n",
    "gt_files, gt_calib, im_sizes, im_files, cams = read_file_data(test_files, gt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.     5.721  5.738 ... 77.793 78.228 78.445]\n"
     ]
    }
   ],
   "source": [
    "gt_depths = []\n",
    "gt_intrinsics = []\n",
    "num_test = len(im_files)\n",
    "for t_id in range(num_test):\n",
    "    camera_id = cams[t_id]\n",
    "    depth = generate_depth_map(gt_calib[t_id], \n",
    "                               gt_files[t_id], \n",
    "                               im_sizes[t_id], \n",
    "                               camera_id, \n",
    "                               False, \n",
    "                               True)\n",
    "    gt_depths.append(depth.astype(np.float32))\n",
    "    \n",
    "    cam2cam = read_calib_file(gt_calib[t_id] + 'calib_cam_to_cam.txt')\n",
    "    P_rect = cam2cam['P_rect_0'+str(camera_id)].reshape(3,4)\n",
    "    intrinsics = P_rect[:3, :3]\n",
    "    gt_intrinsics.append(intrinsics)\n",
    "depth0 = gt_depths[0]\n",
    "print(np.unique(depth0))\n",
    "# cmat = gt_intrinsics[0]\n",
    "# len(gt_intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SfMLearner import SfMLearner\n",
    "img_height = 128\n",
    "img_width = 416\n",
    "batch_size = 4\n",
    "\n",
    "sfm = SfMLearner()\n",
    "sfm.setup_inference(img_height=img_height,\n",
    "img_width=img_width,\n",
    "batch_size=batch_size,\n",
    "mode='norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver([var for var in tf.model_variables()]) \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../MODEL-RESERVE/segedge-0.8/model.latest\n",
      "processing norm-verify: 0/697\n",
      "processing norm-verify: 100/697\n",
      "processing norm-verify: 200/697\n",
      "processing norm-verify: 300/697\n",
      "processing norm-verify: 400/697\n",
      "processing norm-verify: 500/697\n",
      "processing norm-verify: 600/697\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as pil\n",
    "ckpt_file='../MODEL-RESERVE/segedge-0.8/model.latest'\n",
    "output_file = './results/norm-verify.npy'\n",
    "gt_norm_file = './results/norm-verify-gt.npy'\n",
    "basename = 'norm-verify'\n",
    "val_data_dir = '../raw_data_downloader/kitti-val/'\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, ckpt_file)\n",
    "    pred_norms = []\n",
    "    gt_norms =[]\n",
    "    for t in range(0, len(test_files),batch_size):\n",
    "#         if(t>3):\n",
    "#             break;\n",
    "        if t % 100 == 0:\n",
    "            print('processing %s: %d/%d' % (basename, t, len(test_files)))\n",
    "        inputs = np.zeros((batch_size, img_height, img_width, 3), dtype=np.uint8)\n",
    "        input_depths = np.zeros((batch_size, img_height, img_width), dtype=np.uint8)\n",
    "        input_intrinsics= np.zeros((batch_size, 3, 3),dtype=np.float32)\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            idx = t + b\n",
    "            if idx >= len(test_files):\n",
    "                break\n",
    "            raw_im = pil.open(val_data_dir + test_files[idx])\n",
    "            scaled_im = raw_im.resize((img_width, img_height), pil.ANTIALIAS)\n",
    "            inputs[b] = np.array(scaled_im)\n",
    "            \n",
    "            # convert values to 0 - 255 int8 format\n",
    "            formatted = (gt_depths[idx] * 255 / np.max(gt_depths[idx])).astype('uint8')\n",
    "            gt_depth_img = pil.fromarray(formatted)\n",
    "            \n",
    "            input_depths[b] = np.array(gt_depth_img.resize((img_width, img_height),\\\n",
    "                                                           pil.NEAREST))\n",
    "#             input_depths[b] = (input_depths[b] * 255.0 / np.max(input_depths[b])).astype('uint8')\n",
    "            \n",
    "            input_intrinsics[b] = gt_intrinsics[idx]\n",
    "#             print(\"====raw image=====\")\n",
    "#             print(np.unique(raw_im))\n",
    "#             print(\"====gt depth=====\")\n",
    "#             print(np.unique(input_depths[b]))\n",
    "#             print(\"======input_intrinsics===\")\n",
    "#             print(input_intrinsics)\n",
    "        pred = sfm.inference_normal(inputs, input_depths, input_intrinsics, sess)\n",
    "        for b in range(batch_size):\n",
    "            idx = t + b\n",
    "            if idx >= len(test_files):\n",
    "                break\n",
    "            pred_norms.append(pred['normal'][b])\n",
    "            gt_norms.append(pred['gtnormal'][b])\n",
    "#             print(pred['gtnormal'].shape)\n",
    "#             print(np.unique(pred['gtnormal'][b,:,:,0]))\n",
    "#             print(np.unique(pred['normal'][b,:,:,0]))\n",
    "#             print(np.unique(pred['pdepth'][b,:,:,0]))\n",
    "    np.save(output_file, pred_norms)\n",
    "    np.save(gt_norm_file, gt_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal prediction and groundtruth loaded...\n",
      "(697, 128, 416, 3)\n"
     ]
    }
   ],
   "source": [
    "gt_norm = np.load(gt_norm_file)\n",
    "pred_norm = np.load(output_file)\n",
    "print(\"Normal prediction and groundtruth loaded...\")\n",
    "print(gt_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = gt_norm.shape[0]\n",
    "min_limit = -1.1\n",
    "max_limit = 1.1\n",
    "rms     = np.zeros(num_test, np.float32)\n",
    "log_rms = np.zeros(num_test, np.float32)\n",
    "abs_rel = np.zeros(num_test, np.float32)\n",
    "sq_rel  = np.zeros(num_test, np.float32)\n",
    "d1_all  = np.zeros(num_test, np.float32)\n",
    "a1      = np.zeros(num_test, np.float32)\n",
    "a2      = np.zeros(num_test, np.float32)\n",
    "a3      = np.zeros(num_test, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -0.99999994 -0.9999999  ...  0.9999999   0.99999994\n",
      "  1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(pred_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus = 1e-5\n",
    "def m_compute_error(gt, pred):\n",
    "    pred_mask_norm = sum([pred[:,i]**2 for i in range(3)])\n",
    "    gt_mask_norm = sum([gt[:,i]**2 for i in range(3)])\n",
    "    thresh = np.maximum((gt_mask_norm / (pred_mask_norm + plus)), (pred_mask_norm / (gt_mask_norm+plus)))\n",
    "    a1 = (thresh < 0.9   ).mean()\n",
    "    a2 = (thresh < 0.9 ** 2).mean()\n",
    "    a3 = (thresh < 0.9 ** 3).mean()  \n",
    "\n",
    "    rmse = sum((gt[:,i]-pred[:,i])**2 for i in range(3))\n",
    "    rmse = np.sqrt(rmse.mean())\n",
    "    \n",
    "    rmse_log = (np.log(gt_mask_norm + plus) - np.log(pred_mask_norm + plus)) ** 2\n",
    "    rmse_log = np.sqrt(rmse_log.mean())\n",
    "\n",
    "    abs_rel = np.mean(np.sum(np.abs(gt- pred), axis=1) / (np.sum(gt, axis=1) + plus))\n",
    "    \n",
    "    sq_rel = sum((gt[:,i]-pred[:,i])**2 / (np.sum(gt, axis=1) + plus) for i in range(3))\n",
    "    sq_rel = np.mean(sq_rel)\n",
    "    return abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitti_eval.depth_evaluation_utils import compute_errors\n",
    "# num_test = 1\n",
    "for i in range(num_test):    \n",
    "    gt_normi = gt_norm[i]\n",
    "    \n",
    "    pred_normi = np.copy(pred_norm[i])\n",
    "    mask_norm = sum([pred_normi[:,:,i]**2 for i in range(3)])\n",
    "    \n",
    "    mask = np.logical_and(mask_norm > min_limit, \n",
    "                          mask_norm < max_limit)\n",
    "    \n",
    "    # crop used by Garg ECCV16 to reprocude Eigen NIPS14 results\n",
    "    # if used on gt_size 370x1224 produces a crop of [-218, -3, 44, 1180]\n",
    "    gt_height, gt_width = gt_normi.shape[:2]\n",
    "    crop = np.array([0.40810811 * gt_height,  0.99189189 * gt_height,   \n",
    "                     0.03594771 * gt_width,   0.96405229 * gt_width]).astype(np.int32)\n",
    "\n",
    "    crop_mask = np.zeros(mask.shape)\n",
    "    crop_mask[crop[0]:crop[1],crop[2]:crop[3]] = 1\n",
    "    mask = np.logical_and(mask, crop_mask)\n",
    "#     mask = np.ones([gt_height, gt_width]).astype(bool)\n",
    "    # Scale matching\n",
    "#     scalor = np.median(gt_normi[mask])/np.median(pred_normi[mask])\n",
    "#     pred_normi[mask] *= scalor\n",
    "\n",
    "    pred_normi[mask_norm < min_limit,:] = [min_limit]*3\n",
    "    pred_normi[mask_norm > max_limit,:] = [max_limit]*3\n",
    "    abs_rel[i], sq_rel[i], rms[i], log_rms[i], a1[i], a2[i], a3[i] = \\\n",
    "        m_compute_error(gt_normi[mask], pred_normi[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   abs_rel,     sq_rel,        rms,    log_rms,     d1_all,         a1,         a2,         a3\n",
      "145373.0312, 98198.5625,     0.9956,    11.4087,     0.0000,     0.0135,     0.0135,     0.0135\n"
     ]
    }
   ],
   "source": [
    "print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('abs_rel', 'sq_rel', 'rms', 'log_rms', 'd1_all', 'a1', 'a2', 'a3'))\n",
    "print(\"{:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}\".format(abs_rel.mean(), sq_rel.mean(), rms.mean(), log_rms.mean(), d1_all.mean(), a1.mean(), a2.mean(), a3.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(tfboys)",
   "language": "python",
   "name": "tfboys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
